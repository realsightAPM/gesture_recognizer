{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "\n",
    "from multiprocessing import Queue\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "\n",
    "from numpy.linalg import norm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics.scorer import accuracy_scorer\n",
    "\n",
    "from utils import get_cache, set_cache\n",
    "\n",
    "path = 'LP_data/dataset/P{}/G{}/R{}_{}.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 1000\n",
      "Finished 1000 / 1000\n",
      "Finished 1000 / 1000\n"
     ]
    }
   ],
   "source": [
    "training_lpaths = []\n",
    "training_rpaths = []\n",
    "labels = []\n",
    "for p in range(1, 5):\n",
    "    for g in range(1, 11):\n",
    "        for r in range(1, 26):\n",
    "            fname = path.format(p, g, r, 'l')\n",
    "            training_lpaths.append(fname)\n",
    "            fname = path.format(p, g, r, 'r')\n",
    "            training_rpaths.append(fname)\n",
    "            labels.append(g)\n",
    "\n",
    "total = len(labels)\n",
    "print('Total images: {}'.format(total))\n",
    "\n",
    "\n",
    "def preprocess_img(current, path):\n",
    "    data = cv2.imread(path, 0)\n",
    "    # data = cv2.fastNlMeansDenoising(data)\n",
    "    return (current, data)\n",
    "\n",
    "\n",
    "\n",
    "def get_imgs(training_paths, name, load_cache=True):\n",
    "    imgs = get_cache(name)\n",
    "    if not load_cache or imgs is None:\n",
    "        imgs = [None for k in range(total)]\n",
    "        tasks = []\n",
    "        def callback(future):\n",
    "            idx, data = future.result()\n",
    "            imgs[idx] = data\n",
    "        with ProcessPoolExecutor() as executor:\n",
    "            for idx, p in enumerate(training_lpaths):\n",
    "                future = executor.submit(preprocess_img, idx, p)\n",
    "                future.add_done_callback(callback)\n",
    "                tasks.append(future)\n",
    "            while True:\n",
    "                finished = sum(f.done() for f in tasks)\n",
    "                sys.stdout.flush()\n",
    "                sys.stdout.write('Finished {:>4d} / {:>4d}\\r'.format(finished, total))\n",
    "                if all(f.done() for f in tasks):\n",
    "                    print()\n",
    "                    break\n",
    "                time.sleep(1)\n",
    "        set_cache(imgs, name)\n",
    "    return imgs\n",
    "\n",
    "\n",
    "limgs = get_imgs(training_lpaths, 'limgs', False)\n",
    "rimgs = get_imgs(training_rpaths, 'rimgs', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def hog(digits, cellx=20, celly=20):\n",
    "    samples = []\n",
    "    for current, img in enumerate(digits, 1):\n",
    "        w, h = img.shape\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write('Processing {:>4d} / {:>4d}\\r'.format(current, total))\n",
    "        gx = cv2.Sobel(img, cv2.CV_32F, 1, 0)\n",
    "        gy = cv2.Sobel(img, cv2.CV_32F, 0, 1)\n",
    "        mag, ang = cv2.cartToPolar(gx, gy)\n",
    "        bin_n = 16\n",
    "        bin = np.int32(bin_n*ang/(2*np.pi))\n",
    "        bin_cells = []\n",
    "        mag_cells = []\n",
    "        cellxn = w // cellx\n",
    "        cellyn = h // celly\n",
    "        for x in range(cellxn+1):\n",
    "            for y in range(cellyn+1):\n",
    "                bin_cells.append(bin[x*cellx:(x+1)*cellx, y*celly:(y+1)*celly])\n",
    "                mag_cells.append(mag[x*cellx:(x+1)*cellx, y*celly:(y+1)*celly])\n",
    "        hists = [np.bincount(b.ravel(), m.ravel(), bin_n) for b, m in zip(bin_cells, mag_cells)]\n",
    "        hist = np.hstack(hists)\n",
    "\n",
    "        # transform to Hellinger kernel\n",
    "        eps = 1e-7\n",
    "        hist /= hist.sum() + eps\n",
    "        hist = np.sqrt(hist)\n",
    "        hist /= norm(hist) + eps\n",
    "\n",
    "        samples.append(hist)\n",
    "    print('\\n', samples[0].shape)\n",
    "    return np.float32(samples)\n",
    "\n",
    "\n",
    "def hog_single(idx, img, cellx=20, celly=20):\n",
    "    w, h = img.shape\n",
    "    gx = cv2.Sobel(img, cv2.CV_32F, 1, 0)\n",
    "    gy = cv2.Sobel(img, cv2.CV_32F, 0, 1)\n",
    "    mag, ang = cv2.cartToPolar(gx, gy)\n",
    "    bin_n = 16\n",
    "    bin = np.int32(bin_n*ang/(2*np.pi))\n",
    "    bin_cells = []\n",
    "    mag_cells = []\n",
    "    cellxn = w // cellx\n",
    "    cellyn = h // celly\n",
    "    for x in range(cellxn+1):\n",
    "        for y in range(cellyn+1):\n",
    "            bin_cells.append(bin[x*cellx:(x+1)*cellx, y*celly:(y+1)*celly])\n",
    "            mag_cells.append(mag[x*cellx:(x+1)*cellx, y*celly:(y+1)*celly])\n",
    "    hists = [np.bincount(b.ravel(), m.ravel(), bin_n) for b, m in zip(bin_cells, mag_cells)]\n",
    "    hist = np.hstack(hists)\n",
    "    # transform to Hellinger kernel\n",
    "    eps = 1e-7\n",
    "    hist /= hist.sum() + eps\n",
    "    hist = np.sqrt(hist)\n",
    "    hist /= norm(hist) + eps\n",
    "    return (idx, np.float32(hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 1000 / 1000\n",
      "Finished 1000 / 1000\n"
     ]
    }
   ],
   "source": [
    "def get_hog_imgs(imgs, name, load_cache=True):\n",
    "    hog_imgs = get_cache(name)\n",
    "    if not load_cache or hog_limgs is None: \n",
    "        hog_imgs = [None for k in range(total)]\n",
    "        tasks = []\n",
    "        def hog_callback(future):\n",
    "            idx, data = future.result()\n",
    "            hog_imgs[idx] = data\n",
    "        with ProcessPoolExecutor() as executor:\n",
    "            for idx, img in enumerate(imgs):\n",
    "                future = executor.submit(hog_single, idx, img)\n",
    "                future.add_done_callback(hog_callback)\n",
    "                tasks.append(future)\n",
    "            while True:\n",
    "                finished = sum(f.done() for f in tasks)\n",
    "                sys.stdout.flush()\n",
    "                sys.stdout.write('Finished {:>4d} / {:>4d}\\r'.format(finished, total))\n",
    "                if finished == total:\n",
    "                    print()\n",
    "                    break\n",
    "                time.sleep(1)\n",
    "        set_cache(hog_imgs, name)\n",
    "    return hog_imgs\n",
    "\n",
    "\n",
    "hog_limgs = get_hog_imgs(limgs, 'hog_limgs', False)\n",
    "hog_rimgs = get_hog_imgs(rimgs, 'hog_rimgs', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round  1 Accuracy: 70.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fe155468c6db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eta'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'silent'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'objective'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'multi:softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num_class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mnum_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for i in range(20):\n",
    "    X_ltrain, X_ltest, X_rtrain, X_rtest, y_train, y_test = train_test_split(hog_limgs, hog_rimgs, labels, test_size=0.2)\n",
    "    X_train = np.append(np.array(X_ltrain), np.array(X_rtrain), axis=1)\n",
    "    X_test = np.append(np.array(X_ltest), np.array(X_rtest), axis=1)\n",
    "    y_train = np.array(y_train)-1\n",
    "    y_test = np.array(y_test)-1\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    watchlist = [(dtrain, 'train'), (dtest, 'test')]\n",
    "    param = {'max_depth': 2, 'eta': 1, 'silent': 1, 'objective': 'multi:softmax', 'num_class': 10}\n",
    "    num_round = 50\n",
    "    bst = xgb.train(param, dtrain, num_round)\n",
    "    preds = bst.predict(dtest)\n",
    "    accuracy = np.sum(preds == y_test) / len(y_test)\n",
    "    res.append(accuracy)\n",
    "    print('Round {:2d} Accuracy: {:5.2%}'.format(i+1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "res = np.array(res)\n",
    "print()\n",
    "print('Mean: {:>5.2%}'.format(res.mean()))\n",
    "print('Max: {:>5.2%}'.format(res.max()))\n",
    "print('Min: {:>5.2%}'.format(res.min()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
